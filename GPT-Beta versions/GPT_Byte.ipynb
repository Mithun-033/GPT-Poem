{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchinfo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2tjYJUz7MFA","outputId":"47a1cf8f-d548-4902-ecda-e8d3cdca882f","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T04:36:08.150695Z","iopub.execute_input":"2026-01-30T04:36:08.150953Z","iopub.status.idle":"2026-01-30T04:36:12.547232Z","shell.execute_reply.started":"2026-01-30T04:36:08.150901Z","shell.execute_reply":"2026-01-30T04:36:12.546368Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.pre_tokenizers import ByteLevel\nfrom tokenizers.trainers import BpeTrainer\nimport torch\nimport torch.nn as nn\nfrom torchinfo import summary\nimport time\nimport math\nfrom torch.optim.lr_scheduler import LambdaLR","metadata":{"id":"wcNemdfctU_w","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:32.939526Z","iopub.execute_input":"2026-01-30T13:12:32.940082Z","iopub.status.idle":"2026-01-30T13:12:32.944089Z","shell.execute_reply.started":"2026-01-30T13:12:32.940053Z","shell.execute_reply":"2026-01-30T13:12:32.943334Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"yhSau1s8ZfNA","outputId":"ee84ad79-005d-45bf-95e9-d93558628e37","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:34.703532Z","iopub.execute_input":"2026-01-30T13:12:34.703828Z","iopub.status.idle":"2026-01-30T13:12:34.708975Z","shell.execute_reply.started":"2026-01-30T13:12:34.703802Z","shell.execute_reply":"2026-01-30T13:12:34.708281Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"!curl -L -o poem-dataset.zip \\\nhttps://www.kaggle.com/api/v1/datasets/download/marufchowdhury/poem-dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiHWwhB0togE","outputId":"e3435dd8-4aca-4f05-ca45-775d7f2db152","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T04:36:41.612331Z","iopub.execute_input":"2026-01-30T04:36:41.613024Z","iopub.status.idle":"2026-01-30T04:36:42.402552Z","shell.execute_reply.started":"2026-01-30T04:36:41.612983Z","shell.execute_reply":"2026-01-30T04:36:42.401659Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 10.3M  100 10.3M    0     0  18.0M      0 --:--:-- --:--:-- --:--:-- 57.5M\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!unzip poem-dataset.zip\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1boynZ04t9vB","outputId":"87687e7d-5a61-469b-9593-956ecfef7dec","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T04:36:45.399499Z","iopub.execute_input":"2026-01-30T04:36:45.399822Z","iopub.status.idle":"2026-01-30T04:36:45.790027Z","shell.execute_reply.started":"2026-01-30T04:36:45.399790Z","shell.execute_reply":"2026-01-30T04:36:45.789279Z"}},"outputs":[{"name":"stdout","text":"Archive:  poem-dataset.zip\n  inflating: Poems_Dataset.csv       \n  inflating: poemDatasetWithSummary.csv  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df=pd.read_csv(\"Poems_Dataset.csv\")\ndf=df[\"Poem Content\"]\ndata=df.tolist()\n","metadata":{"id":"tUbDM-EOuWcY","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:38.556454Z","iopub.execute_input":"2026-01-30T13:12:38.557095Z","iopub.status.idle":"2026-01-30T13:12:38.786961Z","shell.execute_reply.started":"2026-01-30T13:12:38.557068Z","shell.execute_reply":"2026-01-30T13:12:38.785632Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"#Hyper Parameters\ncontext_window_length=128\nbatch_size=256\nn_embed=288\nn_head=9\nn_layers=9\nv_size=9000\nhead_size=n_embed//n_head","metadata":{"id":"vRU-IZWrugfs","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:41.348378Z","iopub.execute_input":"2026-01-30T13:12:41.349114Z","iopub.status.idle":"2026-01-30T13:12:41.352710Z","shell.execute_reply.started":"2026-01-30T13:12:41.349083Z","shell.execute_reply":"2026-01-30T13:12:41.352131Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"tokenizer=Tokenizer(BPE())\ntokenizer.pre_tokenizer=ByteLevel(add_prefix_space=True)\ntrainer=BpeTrainer(vocab_size=v_size)\ntokenizer.train_from_iterator(data,trainer)","metadata":{"id":"2L-z8OqVmac5","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:43.784697Z","iopub.execute_input":"2026-01-30T13:12:43.785003Z","iopub.status.idle":"2026-01-30T13:12:48.351092Z","shell.execute_reply.started":"2026-01-30T13:12:43.784978Z","shell.execute_reply":"2026-01-30T13:12:48.350441Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"out=tokenizer.encode(\"hello my guy how are you\")\nout.tokens,out.ids\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uilE4AdCoxN7","outputId":"264f84cb-801f-4898-fe83-0da3ff6ece0d","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:51.275790Z","iopub.execute_input":"2026-01-30T13:12:51.276450Z","iopub.status.idle":"2026-01-30T13:12:51.281568Z","shell.execute_reply.started":"2026-01-30T13:12:51.276422Z","shell.execute_reply":"2026-01-30T13:12:51.280744Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"(['Ġhell', 'o', 'Ġmy', 'Ġguy', 'Ġhow', 'Ġare', 'Ġyou'],\n [2368, 78, 280, 5194, 588, 363, 257])"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"all_ids=[]\n\nfor s in data:\n    all_ids.extend(tokenizer.encode(s).ids)\n\nidss=torch.tensor(all_ids,dtype=torch.long).to(device)","metadata":{"id":"J9gzukuMDzFG","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:12:53.826204Z","iopub.execute_input":"2026-01-30T13:12:53.826503Z","iopub.status.idle":"2026-01-30T13:13:06.888286Z","shell.execute_reply.started":"2026-01-30T13:12:53.826479Z","shell.execute_reply":"2026-01-30T13:13:06.887715Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"len(idss)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o27nzmcAco9N","outputId":"7ac849e7-e5e2-4ecb-c7ea-fd093aea6d3b","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:11.146580Z","iopub.execute_input":"2026-01-30T13:13:11.147274Z","iopub.status.idle":"2026-01-30T13:13:11.151682Z","shell.execute_reply.started":"2026-01-30T13:13:11.147245Z","shell.execute_reply":"2026-01-30T13:13:11.151094Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"5462341"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"\nids=idss[:1300000]\nlen(ids)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCPKXJu9E7_4","outputId":"96a7dfb2-35c1-4e36-beeb-5cd50cc4f6ac","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:28.486287Z","iopub.execute_input":"2026-01-30T13:13:28.486580Z","iopub.status.idle":"2026-01-30T13:13:28.491255Z","shell.execute_reply.started":"2026-01-30T13:13:28.486556Z","shell.execute_reply":"2026-01-30T13:13:28.490707Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"1300000"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"def generator(ids,batch_size,cwl):\n    X=[]\n    Y=[]\n    count=0\n\n    for i in range(len(ids)-cwl):\n        X.append(ids[i:i+cwl])\n        Y.append(ids[i+1:i+cwl+1])\n        count+=1\n\n        if count==batch_size:\n            yield torch.stack(X).to(device),torch.stack(Y).to(device)\n            X=[]\n            Y=[]\n            count=0","metadata":{"id":"907QdFNEuzYO","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:34.257772Z","iopub.execute_input":"2026-01-30T13:13:34.258650Z","iopub.status.idle":"2026-01-30T13:13:34.263637Z","shell.execute_reply.started":"2026-01-30T13:13:34.258618Z","shell.execute_reply":"2026-01-30T13:13:34.262872Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self,head_size):\n        super().__init__()\n        self.key=nn.Linear(n_embed,head_size) #(B,T,C)-->(B,T,H)\n        self.query=nn.Linear(n_embed,head_size) #(B,T,C)-->(B,T,H)\n        self.value=nn.Linear(n_embed,head_size)  #(B,T,C)-->(B,T,H\n        self.dropout=nn.Dropout(0.1)\n\n    def forward(self,x):\n        k=self.key(x)     #(B,T,H)\n        q=self.query(x)   #(B,T,H)\n        v=self.value(x)   #(B,T,H)\n\n        # Do Dot product of k and q\n\n        weights=k@q.transpose(-2,-1)*head_size**-0.5  # (B,T,H) x (B,H,T) --> (B,T,T)\n        T=x.size(1)\n        mask=torch.tril(torch.ones(T,T,device=x.device))\n        weights=weights.masked_fill(mask==0,float('-inf'))\n        weights=nn.functional.softmax(weights,dim=-1)\n        weights = self.dropout(weights)\n\n        output=weights@v #(B,T,T) x (B,T,H) --> (B,T,H)\n        return output","metadata":{"id":"YI8G4WR2rku9","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:36.163006Z","iopub.execute_input":"2026-01-30T13:13:36.163783Z","iopub.status.idle":"2026-01-30T13:13:36.203142Z","shell.execute_reply.started":"2026-01-30T13:13:36.163752Z","shell.execute_reply":"2026-01-30T13:13:36.202362Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"class MultiHead(nn.Module):\n    def __init__(self,n_head,head_size):\n        super().__init__()\n        self.heads=nn.ModuleList([AttentionHead(head_size) for _ in range(n_head)])\n        self.project=nn.Linear(n_head*head_size,n_embed)\n        self.dropout=nn.Dropout(0.1)\n    def forward(self,x):\n        out=torch.cat([h(x) for h in self.heads],dim=-1)  # (B,T,H*N)\n        #out=self.project(out)  # (B,T,H*N) --> (B,T,C) \n        out = self.dropout(out)\n        return out","metadata":{"id":"W_ekLv4AxyUy","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:38.656318Z","iopub.execute_input":"2026-01-30T13:13:38.656610Z","iopub.status.idle":"2026-01-30T13:13:38.662495Z","shell.execute_reply.started":"2026-01-30T13:13:38.656586Z","shell.execute_reply":"2026-01-30T13:13:38.661736Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.FF=nn.Sequential(\n            nn.Linear(n_embed,3*n_embed),\n            nn.ReLU(),\n            nn.Linear(3*n_embed,n_embed),\n            nn.Dropout()\n        )\n\n    def forward(self,x):\n        return self.FF(x)","metadata":{"id":"0SkDUQSkzaDf","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:40.924609Z","iopub.execute_input":"2026-01-30T13:13:40.925085Z","iopub.status.idle":"2026-01-30T13:13:40.929582Z","shell.execute_reply.started":"2026-01-30T13:13:40.925059Z","shell.execute_reply":"2026-01-30T13:13:40.928825Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self,n_embed,n_head):\n        super().__init__()\n        head_size=n_embed//n_head\n        self.SelfAtt = MultiHead(n_head, head_size)\n        self.ffwd = FeedForward()\n        self.ln1 = nn.LayerNorm(n_embed)\n        self.ln2 = nn.LayerNorm(n_embed)\n\n    def forward(self,x):\n        x = x + self.SelfAtt(self.ln1(x)) + self.ffwd(self.ln2(x))\n        return x  #(B,T,C)","metadata":{"id":"tvYtXEmo05oI","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:43.153639Z","iopub.execute_input":"2026-01-30T13:13:43.154429Z","iopub.status.idle":"2026-01-30T13:13:43.159621Z","shell.execute_reply.started":"2026-01-30T13:13:43.154397Z","shell.execute_reply":"2026-01-30T13:13:43.158889Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embed=nn.Embedding(v_size,n_embed)  # (B,T) --> (B,T,C)\n        self.pos_embed=nn.Embedding(context_window_length,n_embed) # (T) --> (T,C)\n\n        self.blocks=nn.Sequential(*[Block(n_embed,n_head) for _ in range(n_layers)])\n        self.final_layernorm = nn.LayerNorm(n_embed) # final layer norm\n        self.lm_head = nn.Linear(n_embed, v_size)\n\n    def forward(self,x):\n        # x ==> (B,T)\n\n        tok_embeds=self.embed(x) # (B,T,C)\n        pos_embeds=self.pos_embed(torch.arange(x.size(1),device=x.device)) #(T,C)\n        x=tok_embeds + pos_embeds # pos_embed r broadcasted and added to every batch element\n\n        x=self.blocks(x)\n        x=self.final_layernorm(x)\n        logits=self.lm_head(x)\n\n        return logits\n\n\n    @torch.no_grad()\n    def generate(model,idx,max_new_tokens):\n        for _ in range(max_new_tokens):\n            if idx.size(1)>context_window_length:\n                idx_cond=idx[:,-context_window_length:]\n            else:\n                idx_cond=idx\n\n            logits=model(idx_cond)\n            probs=torch.softmax(logits[:,-1,:],dim=-1)\n            next_token=torch.multinomial(probs,1)\n            idx=torch.cat((idx,next_token),dim=1)\n\n        return idx\n","metadata":{"id":"fuWPQlPN21Pf","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:45.332169Z","iopub.execute_input":"2026-01-30T13:13:45.332854Z","iopub.status.idle":"2026-01-30T13:13:45.340153Z","shell.execute_reply.started":"2026-01-30T13:13:45.332825Z","shell.execute_reply":"2026-01-30T13:13:45.339462Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"model=GPT().to(device)\nmodel=torch.compile(model)\noptimizer=torch.optim.AdamW(model.parameters(),lr=0.00007,fused=True)\ncriterion=nn.CrossEntropyLoss()\ndef lr_lambda(epoch):\n    return 0.5*(1+math.cos(math.pi*epoch/epochs))\n\nscheduler=LambdaLR(optimizer,lr_lambda)\nepochs=20","metadata":{"id":"M__qjCFr6hpt","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:13:59.841189Z","iopub.execute_input":"2026-01-30T13:13:59.841890Z","iopub.status.idle":"2026-01-30T13:13:59.994471Z","shell.execute_reply.started":"2026-01-30T13:13:59.841861Z","shell.execute_reply":"2026-01-30T13:13:59.993295Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"summary(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yG42afNYBChY","outputId":"fc0410f7-0a63-4ea1-f78a-a8b82fee215d","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:14:01.836225Z","iopub.execute_input":"2026-01-30T13:14:01.836929Z","iopub.status.idle":"2026-01-30T13:14:01.885900Z","shell.execute_reply.started":"2026-01-30T13:14:01.836884Z","shell.execute_reply":"2026-01-30T13:14:01.885223Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nOptimizedModule                                         --\n├─GPT: 1-1                                              --\n│    └─Embedding: 2-1                                   2,592,000\n│    └─Embedding: 2-2                                   36,864\n│    └─Sequential: 2-3                                  --\n│    │    └─Block: 3-1                                  832,896\n│    │    └─Block: 3-2                                  832,896\n│    │    └─Block: 3-3                                  832,896\n│    │    └─Block: 3-4                                  832,896\n│    │    └─Block: 3-5                                  832,896\n│    │    └─Block: 3-6                                  832,896\n│    │    └─Block: 3-7                                  832,896\n│    │    └─Block: 3-8                                  832,896\n│    │    └─Block: 3-9                                  832,896\n│    └─LayerNorm: 2-4                                   576\n│    └─Linear: 2-5                                      2,601,000\n================================================================================\nTotal params: 12,726,504\nTrainable params: 12,726,504\nNon-trainable params: 0\n================================================================================"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"scaler=torch.cuda.amp.GradScaler()\n\nfor i in range(epochs):\n    step=0\n    start_epoch=time.time()\n    last_print_time=start_epoch\n\n    for x,y in generator(ids,batch_size,context_window_length):\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.cuda.amp.autocast():\n            logits=model(x)\n            logits=logits.view(-1,logits.size(-1))\n            y=y.view(-1)\n            loss=criterion(logits,y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        step+=1\n        if step%150==0:\n            now=time.time()\n            print(\n                f\"Epoch: {i+1}, \"\n                f\"Step: {step}, \"\n                f\"Loss: {loss.item():.4f}, \"\n                f\"Time/100 batches: {(now-last_print_time):.2f} sec\")\n            last_print_time=now\n    scheduler.step()\n    \n    end_epoch=time.time()\n    print(f\"Epoch {i+1} total time: {(end_epoch-start_epoch):.2f} sec\")\n    torch.save(model.state_dict(),f\"Model_epoch_{i+1}.pt\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMOyq2NC7d6n","outputId":"40e0f6f7-78bd-4870-bd8e-f3e975a8f5d1","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T13:14:29.189862Z","iopub.execute_input":"2026-01-30T13:14:29.190608Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/564485647.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler=torch.cuda.amp.GradScaler()\n/tmp/ipykernel_55/564485647.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nException ignored in: <function ExactWeakKeyDictionary.__setitem__.<locals>.<lambda> at 0x7b2e21a0f9c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 954, in <lambda>\n    self.refs[idx] = weakref.ref(key, lambda ref: self._remove_id(idx))\n\nKeyboardInterrupt: \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"val_ids=idss[-20000:-1]\nlen(val_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T12:48:18.417816Z","iopub.execute_input":"2026-01-30T12:48:18.418591Z","iopub.status.idle":"2026-01-30T12:48:18.423489Z","shell.execute_reply.started":"2026-01-30T12:48:18.418560Z","shell.execute_reply":"2026-01-30T12:48:18.422862Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"19999"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"for i in range(1,28):\n    temp=torch.load(f\"Model_epoch_{i}.pt\",map_location=device)\n    temp={k.replace(\"_orig_mod.\",\"\"):v for k,v in temp.items()}\n    model=GPT()\n    model.load_state_dict(temp)\n    model.to(device)\n    avg_loss=0\n    count=0\n    with torch.no_grad():\n        model.eval()\n        for x,y in generator(val_ids,batch_size,context_window_length):\n            logits=model(x)\n            logits=logits.view(-1,logits.size(-1))\n            y=y.view(-1)\n            loss=criterion(logits,y)\n            count+=1\n            avg_loss+=loss.item()\n\n    print(f\"Model_{i} Val Loss:{avg_loss/count}\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T12:49:09.732165Z","iopub.execute_input":"2026-01-30T12:49:09.732463Z","iopub.status.idle":"2026-01-30T12:57:43.626365Z","shell.execute_reply.started":"2026-01-30T12:49:09.732437Z","shell.execute_reply":"2026-01-30T12:57:43.625708Z"}},"outputs":[{"name":"stdout","text":"Model_1 Val Loss:6.1067119751657755\nModel_2 Val Loss:5.841304796082633\nModel_3 Val Loss:5.666963466576168\nModel_4 Val Loss:5.545412727764675\nModel_5 Val Loss:5.459126625742231\nModel_6 Val Loss:5.394868578229632\nModel_7 Val Loss:5.344340511730739\nModel_8 Val Loss:5.30354768889291\nModel_9 Val Loss:5.269190847873688\nModel_10 Val Loss:5.240001865795681\nModel_11 Val Loss:5.215300704751696\nModel_12 Val Loss:5.1942658339227945\nModel_13 Val Loss:5.175960012844631\nModel_14 Val Loss:5.160851972443717\nModel_15 Val Loss:5.149416131632669\nModel_16 Val Loss:5.14115423815591\nModel_17 Val Loss:5.136325606278011\nModel_18 Val Loss:5.133300117083958\nModel_19 Val Loss:5.132233653749738\nModel_20 Val Loss:5.1347266009875705\nModel_21 Val Loss:5.139067879744938\nModel_22 Val Loss:5.144578048161098\nModel_23 Val Loss:5.15180368082864\nModel_24 Val Loss:5.160773115498679\nModel_25 Val Loss:5.17087288413729\nModel_26 Val Loss:5.1827168720109125\nModel_27 Val Loss:5.194707700184414\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"while True:\n    x=input(\"Enter starting text:\")\n    y=tokenizer.encode(x).ids\n    context=torch.tensor([y],device=device)\n    print(tokenizer.decode(model.generate(context, max_new_tokens=50)[0].tolist()))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"ua4xME3JyJbg","outputId":"fcf8373f-3a12-45a3-8eac-ca8bea16c360"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter starting text:hello\n","hell o ’ w D u cour ’ come je ’ ro ’ ty ’ u y ’ i ’ ’ ele ky ex ä ’ min ex ’ mo m ’ t ’ j ’ ti ’ m ä ny j not earth ä w y i ’ a ’ i\n","Enter starting text:sun rises \n","sun rises in k ids St ted out . A A point lo ch , - be er ers , T H ching to see more , W of pur P ass down from its corner , n be every sa ace your thr w al th the sweet i y ,\n","Enter starting text:sagarika\n","s ag ar i k a los ces their And Com i ó aws B es ition i y a la i j an am ty or a bled a j ic o ch once you can the building i ol er j u yo ec i en , C R una e a their que\n"]},{"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2162762703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter starting text:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"execution_count":null}]}