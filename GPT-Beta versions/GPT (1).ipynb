{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2tjYJUz7MFA",
        "outputId": "581c2b61-29c2-4178-db59-c5a3f4728b2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wcNemdfctU_w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o poem-dataset.zip \\\n",
        "https://www.kaggle.com/api/v1/datasets/download/marufchowdhury/poem-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiHWwhB0togE",
        "outputId": "c6bbc270-36a7-4922-e621-be0039e45bdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 10.3M  100 10.3M    0     0  4009k      0  0:00:02  0:00:02 --:--:-- 5616k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip poem-dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1boynZ04t9vB",
        "outputId": "88e7070d-69b6-4f7a-d34f-48553f5f94c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  poem-dataset.zip\n",
            "  inflating: Poems_Dataset.csv       \n",
            "  inflating: poemDatasetWithSummary.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Poems_Dataset.csv\")\n",
        "df=df[\"Poem Content\"]\n",
        "data=df.tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "tUbDM-EOuWcY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper Parameters\n",
        "context_window_length=20\n",
        "batch_size=64\n",
        "n_embed=200\n",
        "n_head=5\n",
        "n_layers=5\n",
        "v_size=5000\n",
        "head_size=n_embed//n_head"
      ],
      "metadata": {
        "id": "vRU-IZWrugfs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(BPE())\n",
        "tokenizer.pre_tokenizer=Whitespace()"
      ],
      "metadata": {
        "id": "2L-z8OqVmac5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=BpeTrainer(vocab_size=v_size)\n",
        "tokenizer.train_from_iterator(data,trainer)"
      ],
      "metadata": {
        "id": "AWaFDDXDoE7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=tokenizer.encode(\"hello my guy how are you\")\n",
        "out.tokens,out.ids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uilE4AdCoxN7",
        "outputId": "1ea7779f-87c6-477d-8d3e-6e1f7140bbdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['hell', 'o', 'my', 'gu', 'y', 'how', 'are', 'you'],\n",
              " [3825, 78, 2059, 2571, 88, 2250, 2084, 2042])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(data,batch_size,cwl):\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    count=0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        X.append(data[i:i+cwl])\n",
        "        Y.append(data[i+1:i+cwl+1])\n",
        "        count+=1\n",
        "\n",
        "        if count==batch_size:\n",
        "            yield torch.stack(X,dtype=torch.float32),torch.stack(Y,dtype=torch.float32)\n",
        "            X,Y=[],[]\n",
        "            count=0\n",
        "\n"
      ],
      "metadata": {
        "id": "907QdFNEuzYO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self,head_size):\n",
        "        super().__init__()\n",
        "        self.key=nn.Linear(n_embed,head_size) #(B,T,C)-->(B,T,H)\n",
        "        self.query=nn.Linear(n_embed,head_size) #(B,T,C)-->(B,T,H)\n",
        "        self.value=nn.Linear(n_embed,head_size)  #(B,T,C)-->(B,T,H)\n",
        "\n",
        "    def forward(self,x):\n",
        "        k=self.key(x)     #(B,T,H)\n",
        "        q=self.query(x)   #(B,T,H)\n",
        "        v=self.value(x)   #(B,T,H)\n",
        "\n",
        "        # Do Dot product of k and q\n",
        "\n",
        "        weights=k@q.transpose(-2,-1)*head_size**-0.5  # (B,T,H) x (B,H,T) --> (B,T,T)\n",
        "        weights=weights.masked_fill(torch.tril(torch.ones((context_window_length,context_window_length))==0,float(\"-inf\")))\n",
        "        weights=nn.functional.softmax(weights,dim=-1)\n",
        "        weights=nn.Dropout(weights,0.1)\n",
        "\n",
        "        output=weights@v #(B,T,T) x (B,T,H) --> (B,T,H)\n",
        "        return output"
      ],
      "metadata": {
        "id": "YI8G4WR2rku9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead(nn.Module):\n",
        "    def __init__(self,n_head,head_size):\n",
        "        super().__init__()\n",
        "        self.heads=nn.ModuleList([AttentionHead(head_size) for _ in range(n_head)])\n",
        "        self.project=nn.Linear(n_head*head_size,n_embed)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out=torch.cat([h(x) for h in self.heads],dim=-1)  # (B,T,H*N)\n",
        "        out=self.project(out)  # (B,T,H*N) --> (B,T,C)\n",
        "        out=nn.Dropout(out,0.1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "W_ekLv4AxyUy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.FF=nn.Sequential(\n",
        "            nn.Linear(n_embed,3*n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(3*n_embed,n_embed),\n",
        "            nn.Dropout()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.FF(x)"
      ],
      "metadata": {
        "id": "0SkDUQSkzaDf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self,n_embed,n_head):\n",
        "        super().__init__()\n",
        "        head_size=n_embed//n_head\n",
        "        self.SelfAtt = MultiHead(n_head, head_size)\n",
        "        self.ffwd = FeedForward()\n",
        "        self.ln1 = nn.LayerNorm(n_embed)\n",
        "        self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x + self.sa(self.ln1(x)) + self.ffwd(self.ln2(x))\n",
        "        return x  #(B,T,C)"
      ],
      "metadata": {
        "id": "tvYtXEmo05oI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed=nn.Embedding(v_size,n_embed)  # (B,T) --> (B,T,C)\n",
        "        self.pos_embed=nn.Embedding(context_window_length,n_embed) # (T) --> (T,C)\n",
        "\n",
        "        self.blocks=nn.Sequential(*[Block(n_embed,n_head) for _ in range(n_layers)])\n",
        "        self.final_layernorm = nn.LayerNorm(n_embed) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embed, v_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x ==> (B,T)\n",
        "\n",
        "        tok_embeds=self.embed(x) # (B,T,C)\n",
        "        pos_embeds=self.pos_embed(torch.arange(context_window_length)) #(T,C)\n",
        "        x=tok_embeds + pos_embeds # pos_embed r broadcasted and added to every batch element\n",
        "\n",
        "        x=self.blocks(x)\n",
        "        x=self.final_layernorm(x)\n",
        "        logits=self.lm_head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(model,idx,max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            if idx.size(1)>context_window_length:\n",
        "                idx_cond=idx[:,-context_window_length:]\n",
        "            else:\n",
        "                idx_cond=idx\n",
        "\n",
        "            logits=model(idx_cond)\n",
        "            probs=torch.softmax(logits[:,-1,:],dim=-1)\n",
        "            next_token=torch.multinomial(probs,1)\n",
        "            idx=torch.cat((idx,next_token),dim=1)\n",
        "\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "fuWPQlPN21Pf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPT()\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr=0.0001)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "M__qjCFr6hpt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG42afNYBChY",
        "outputId": "de8672c6-4950-45ef-8e6d-65885558864a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "GPT                                           --\n",
              "├─Embedding: 1-1                              1,000,000\n",
              "├─Embedding: 1-2                              4,000\n",
              "├─Sequential: 1-3                             --\n",
              "│    └─Block: 2-1                             --\n",
              "│    │    └─MultiHead: 3-1                    160,800\n",
              "│    │    └─FeedForward: 3-2                  240,800\n",
              "│    │    └─LayerNorm: 3-3                    400\n",
              "│    │    └─LayerNorm: 3-4                    400\n",
              "│    └─Block: 2-2                             --\n",
              "│    │    └─MultiHead: 3-5                    160,800\n",
              "│    │    └─FeedForward: 3-6                  240,800\n",
              "│    │    └─LayerNorm: 3-7                    400\n",
              "│    │    └─LayerNorm: 3-8                    400\n",
              "│    └─Block: 2-3                             --\n",
              "│    │    └─MultiHead: 3-9                    160,800\n",
              "│    │    └─FeedForward: 3-10                 240,800\n",
              "│    │    └─LayerNorm: 3-11                   400\n",
              "│    │    └─LayerNorm: 3-12                   400\n",
              "│    └─Block: 2-4                             --\n",
              "│    │    └─MultiHead: 3-13                   160,800\n",
              "│    │    └─FeedForward: 3-14                 240,800\n",
              "│    │    └─LayerNorm: 3-15                   400\n",
              "│    │    └─LayerNorm: 3-16                   400\n",
              "│    └─Block: 2-5                             --\n",
              "│    │    └─MultiHead: 3-17                   160,800\n",
              "│    │    └─FeedForward: 3-18                 240,800\n",
              "│    │    └─LayerNorm: 3-19                   400\n",
              "│    │    └─LayerNorm: 3-20                   400\n",
              "├─LayerNorm: 1-4                              400\n",
              "├─Linear: 1-5                                 1,005,000\n",
              "======================================================================\n",
              "Total params: 4,021,400\n",
              "Trainable params: 4,021,400\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "    step=0\n",
        "    for x,y in generator(data,batch_size,context_window_length):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        logits=model(x)\n",
        "        logits=logits.view(batch_size*context_window_length,n_embed)\n",
        "        y=y.view(batch_size*context_window_length)\n",
        "\n",
        "        loss=criterion(logits,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        step+=1\n",
        "\n",
        "        if step%10==0:\n",
        "            print(f\"Epoch: {i+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long)\n",
        "print(tokenizer.decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "SMOyq2NC7d6n",
        "outputId": "a6844255-8a1a-40c2-a013-8ed0bf899597"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected Tensor as element 0 in argument 0, but got str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1192475124.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_window_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1979686511.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(data, batch_size, cwl)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got str"
          ]
        }
      ]
    }
  ]
}